{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Tuning for KNN-TD(0)\n",
    "\n",
    "*Author: Maleakhi Agung Wijaya*  \n",
    "*Date Created: 05/01/2018*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mountain Car Environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MountainCarEnvironment:\n",
    "    \"\"\"\n",
    "    Description: Environment for Mountain Car problem, adapted from Sutton and Barto's Introduction to Reinforcement Learning.\n",
    "    Author: Maleakhi Agung Wijaya\n",
    "    \"\"\"\n",
    "    VELOCITY_BOUNDARIES = (-0.07, 0.07)\n",
    "    POSITION_BOUNDARIES = (-1.2, 0.6) \n",
    "    \n",
    "    INITIAL_VELOCITY = 0.0\n",
    "    INITIAL_POSITION = -0.5\n",
    "    \n",
    "    REWARD_STEP = -1\n",
    "    REWARD_TERMINAL = 0\n",
    "   \n",
    "    # Constructor for MountainCarEnvironment\n",
    "    # Input: agent for the MountainCarEnvironment\n",
    "    # Output: MountainCarEnvironment object\n",
    "    def __init__(self, car):\n",
    "        self.car = car\n",
    "        self.reset()\n",
    "        \n",
    "    # Compute next state (feature)\n",
    "    # Output: [new velocity, new position]\n",
    "    def nextState(self, action):\n",
    "        # Get current state (velocity, position) and the action chosen by the agent\n",
    "        velocity = self.car.state[0]\n",
    "        position = self.car.state[1]\n",
    "        \n",
    "        # Calculate the new velocity and new position\n",
    "        velocity += action * 0.001 + math.cos(3*position) * (-0.0025)\n",
    "        # Consider boundary for velocity\n",
    "        if (velocity < MountainCarEnvironment.VELOCITY_BOUNDARIES[0]):\n",
    "            velocity = MountainCarEnvironment.VELOCITY_BOUNDARIES[0]\n",
    "        elif (velocity > MountainCarEnvironment.VELOCITY_BOUNDARIES[1]):\n",
    "            velocity = MountainCarEnvironment.VELOCITY_BOUNDARIES[1]\n",
    "            \n",
    "        position += velocity\n",
    "        # Consider boundary for position\n",
    "        if (position < MountainCarEnvironment.POSITION_BOUNDARIES[0]):\n",
    "            position = MountainCarEnvironment.POSITION_BOUNDARIES[0]\n",
    "            velocity = 0\n",
    "        elif (position > MountainCarEnvironment.POSITION_BOUNDARIES[1]):\n",
    "            position = MountainCarEnvironment.POSITION_BOUNDARIES[1]\n",
    "        \n",
    "        new_state = [velocity, position]\n",
    "        return(new_state)\n",
    "    \n",
    "    # Reset to the initial state   \n",
    "    def reset(self):\n",
    "        self.car.state[0] = MountainCarEnvironment.INITIAL_VELOCITY\n",
    "        self.car.state[1] = MountainCarEnvironment.INITIAL_POSITION\n",
    "        \n",
    "    # Give reward for each of the chosen action, depending on what the next state that the agent end up in\n",
    "    # Output: terminal state = 0, non-terminal state = -1\n",
    "    def calculateReward(self):\n",
    "        # Get current position of the agent\n",
    "        position = self.car.state[1]\n",
    "        \n",
    "        # Determine the reward given\n",
    "        if (position >= MountainCarEnvironment.POSITION_BOUNDARIES[1]):\n",
    "            return(MountainCarEnvironment.REWARD_TERMINAL)\n",
    "        else:\n",
    "            return(MountainCarEnvironment.REWARD_STEP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN-TD Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class KNNAgent:\n",
    "    \"\"\"\n",
    "    Description: Mountain Car problem agent based on kNN-TD(0) algorithm \n",
    "    Author: Maleakhi Agung Wijaya\n",
    "    \"\"\"\n",
    "    INITIAL_VELOCITY = 0.0\n",
    "    INITIAL_POSITION = -0.5\n",
    "    INITIAL_VALUE = -1\n",
    "    \n",
    "    ACTIONS = [-1, 0, 1]\n",
    "    GAMMA = 0.995\n",
    "    EPSILON = 0.05\n",
    "    \n",
    "    INDEX_DISTANCE = 0\n",
    "    INDEX_ORIGINAL = 1\n",
    "    INDEX_WEIGHT = 2\n",
    "    \n",
    "    REWARD_STEP = -1\n",
    "    REWARD_TERMINAL = 0\n",
    "    \n",
    "    # Constructor\n",
    "    # Input: size of the storage for previous Q values, parameters for how many neighbours which the agent will choose\n",
    "    def __init__(self, size, k):\n",
    "        self.state = [KNNAgent.INITIAL_VELOCITY, KNNAgent.INITIAL_POSITION]\n",
    "        self.q_storage = []\n",
    "        self.k = k # fixed number of nearest neighbours that we will used\n",
    "        self.alpha = 1 # will be decaying and change later\n",
    "        \n",
    "        # Storage of the k nearest neighbour (data) and weight (inverse of distance) for a particular step\n",
    "        self.knn = []\n",
    "        self.weight = []\n",
    "        \n",
    "        # Initialise the storage with random point \n",
    "        for i in range(size):\n",
    "            initial_action = random.randint(-1, 1)\n",
    "            initial_state = [random.uniform(-0.07, 0.07), random.uniform(-1.2, 0.6)]\n",
    "            \n",
    "            # Each data on the array will consist of state, action pair + value\n",
    "            data = {\"state\": initial_state, \"value\": KNNAgent.INITIAL_VALUE, \"action\": initial_action}\n",
    "            self.q_storage.append(data)\n",
    "    \n",
    "    # Find all index for a given value\n",
    "    # Input: value, list to search\n",
    "    # Output: list of all index where you find that value on the list\n",
    "    def findAllIndex(self, value, list_value):\n",
    "        indices = []\n",
    "        for i in range(len(list_value)):\n",
    "              if (value == list_value[i]):\n",
    "                    indices.append(i)\n",
    "        \n",
    "        return indices\n",
    "    \n",
    "    # Standardise feature vector given\n",
    "    # Input: feature vector to be standardised\n",
    "    # Output: standardised feature vector\n",
    "    def standardiseState(self, state):\n",
    "        standardised_state = []\n",
    "        \n",
    "        # The number is taken from VELOCITY_BOUNDARIES and POSITION_BOUNDARIES using normal standardisation formula\n",
    "        standardised_velocity = 2 * ((state[0]+0.07) / (0.07+0.07)) - 1\n",
    "        standardised_position = 2 * ((state[1]+1.2) / (0.6+1.2)) - 1\n",
    "        \n",
    "        standardised_state.append(standardised_velocity)\n",
    "        standardised_state.append(standardised_position)\n",
    "        \n",
    "        return(standardised_state)\n",
    "    \n",
    "    # Calculate Euclidean distance between 2 vectors\n",
    "    # Input: 2 feature vectors\n",
    "    # Output: distance between them\n",
    "    def calculateDistance(self, vector1, vector2):\n",
    "        return(math.sqrt((vector1[0]-vector2[0])**2 + (vector1[1]-vector2[1])**2))\n",
    "    \n",
    "    # Calculate total weight\n",
    "    # Input: list of weights\n",
    "    # Output: total weight\n",
    "    def calculateTotalWeight(self, weight_list):\n",
    "        total_weight = 0\n",
    "        for i in range(len(weight_list)):\n",
    "            total_weight += weight_list[i][KNNAgent.INDEX_WEIGHT]\n",
    "        \n",
    "        return(total_weight)\n",
    "    \n",
    "    # Apply the kNN algorithm for feature vector and store the data point on the neighbours array\n",
    "    # Input: feature vector of current state, actions array consisting of all possible actions, list that will store knn data and weights data\n",
    "    # Output: vector containing the value of taking each action (left, neutral, right)\n",
    "    def kNNTD(self, state, actions, knn_list, weight_list):\n",
    "        approximate_action = []\n",
    "        \n",
    "        # Get the standardised version of state\n",
    "        standardised_state = self.standardiseState(state)\n",
    "        \n",
    "        # Loop through every element in the storage array and only calculate for particular action\n",
    "        for action in actions:\n",
    "            temp = [] # array consisting of tuple (distance, original index, weight) for each point in the q_storage\n",
    "            for i in range(len(self.q_storage)):\n",
    "                data = self.q_storage[i]\n",
    "                # Only want to calculate the nearest neighbour state which has the same action\n",
    "                if (data[\"action\"] == action):\n",
    "                    vector_2 = data[\"state\"]\n",
    "                    standardised_vector_2 = self.standardiseState(vector_2)\n",
    "                    distance = self.calculateDistance(standardised_state, standardised_vector_2)\n",
    "                    index = i\n",
    "                    weight = 1 / (1+distance**2) # weight formula\n",
    "            \n",
    "                    # Create the tuple and append that to temp\n",
    "                    temp.append(tuple((distance, index, weight)))\n",
    "                else:\n",
    "                    continue\n",
    "        \n",
    "            # After we finish looping through all of the point and calculating the standardise distance,\n",
    "            # Sort the tuple based on the distance and only take k of it and append that to the neighbours array\n",
    "            # We also need to calculate the total weight to make it into valid probability that we can compute it's expectation\n",
    "            sorted_temp = sorted(temp, key=lambda x: x[0])\n",
    "            for i in range(self.k):\n",
    "                try:\n",
    "                    weight_list.append(sorted_temp[i])\n",
    "                    knn_list.append(self.q_storage[sorted_temp[i][KNNAgent.INDEX_ORIGINAL]])\n",
    "                except IndexError:\n",
    "                    sys.exit(0)\n",
    "            \n",
    "            # Calculate the expected value of the action and append it to the approximate_action array\n",
    "            expected_value = 0\n",
    "            total_weight = self.calculateTotalWeight(weight_list[(action+1)*self.k:(action+1)*self.k + self.k])\n",
    "            for i in range((action+1)*self.k, (action+1)*self.k + self.k):\n",
    "                weight = weight_list[i][KNNAgent.INDEX_WEIGHT]\n",
    "                probability = weight / total_weight\n",
    "                expected_value += probability * knn_list[i][\"value\"]\n",
    "                \n",
    "            approximate_action.append(expected_value)\n",
    "        \n",
    "        return(approximate_action)\n",
    "    \n",
    "    # Select which action to choose, whether left, neutral, or right (using epsilon greedy)\n",
    "    # Output: -1 (left), 0 (neutral), 1 (right)\n",
    "    def selectAction(self):\n",
    "        # First call the knn-td algorithm to determine the value of each Q(s,a) pairs\n",
    "        action_value = self.kNNTD(self.state, KNNAgent.ACTIONS, self.knn, self.weight)\n",
    "        \n",
    "        # Use the epsilon-greedy method to choose value\n",
    "        random_number = random.uniform(0.0, 1.0)\n",
    "        if (random_number <= KNNAgent.EPSILON):\n",
    "            action_chosen = random.randint(-1, 1)\n",
    "        else:\n",
    "            # Return the action with highest Q(s,a)\n",
    "            possible_index = self.findAllIndex(max(action_value), action_value)\n",
    "            action_chosen = possible_index[random.randrange(len(possible_index))] - 1\n",
    "        \n",
    "        # Only store chosen data in the knn and weight list\n",
    "        # Clearance step\n",
    "        chosen_knn = []\n",
    "        chosen_weight = []\n",
    "        for i in range(self.k*(action_chosen+1), self.k*(action_chosen+1) + self.k):\n",
    "            chosen_knn.append(self.knn[i])\n",
    "            chosen_weight.append(self.weight[i])\n",
    "        self.knn = chosen_knn\n",
    "        self.weight = chosen_weight\n",
    "\n",
    "        return action_chosen\n",
    "    \n",
    "    # Calculate TD target based on Q Learning/ SARSAMAX\n",
    "    # Input: Immediate reward based on what the environment gave\n",
    "    # Output: TD target based on off policy Q learning\n",
    "    def calculateTDTarget(self, immediate_reward):\n",
    "        # Consider condition on the final state, return 0 immediately\n",
    "        if (immediate_reward == KNNAgent.REWARD_TERMINAL):\n",
    "            return(immediate_reward)\n",
    "        \n",
    "        knn_prime = []\n",
    "        weight_prime = []\n",
    "        action_value = self.kNNTD(self.state, KNNAgent.ACTIONS, knn_prime, weight_prime)\n",
    "        \n",
    "        return(immediate_reward + KNNAgent.GAMMA*max(action_value))\n",
    "    \n",
    "    # Q learning TD updates on every neighbours on the kNN based on the contribution that are calculated using probability weight\n",
    "    # Input: Immediate reward based on what the environment gave\n",
    "    def TDUpdate(self, immediate_reward, alpha):\n",
    "        self.alpha = alpha\n",
    "        # First, calculate the TD target\n",
    "        td_target = self.calculateTDTarget(immediate_reward)\n",
    "        \n",
    "        # Iterate every kNN and update using Q learning method based on the weighting\n",
    "        total_weight = self.calculateTotalWeight(self.weight)\n",
    "        for i in range(len(self.weight)):\n",
    "            index = self.weight[i][KNNAgent.INDEX_ORIGINAL]\n",
    "            probability = self.weight[i][KNNAgent.INDEX_WEIGHT] / total_weight\n",
    "            \n",
    "            # Begin updating\n",
    "            td_error = td_target - self.q_storage[index][\"value\"]\n",
    "            self.q_storage[index][\"value\"] = self.q_storage[index][\"value\"] + self.alpha*td_error*probability\n",
    "        \n",
    "        self.cleanList() # clean list to prepare for another step\n",
    "            \n",
    "    # Clear the knn list and also the weight list\n",
    "    def cleanList(self):\n",
    "        self.knn = []\n",
    "        self.weight = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main purpose of this program is to tune the best k parameter/ number of nearest neighbours to use for the  KNN-TD approach described and implemented on [PNA.ipynb](https://github.com/maleakhiw/Pessimistic-Neighbourhood-Aggregation-for-States-in-Reinforcement-Learning/blob/master/PNA.ipynb). The main approach that is used for this purpose is by trying k (number of nearest neighbours) starting from 4 up to considering all points as neighbours. From there, results are generated and inspected for each k which we will choose the best k leading to convergence. The environment that will be used is Mountain Car."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate decaying alphas\n",
    "# Input: minimum alpha, number of episodes\n",
    "# Output: list containing alpha\n",
    "def generateAlphas(minimum_alpha, n_episodes):\n",
    "    return(np.linspace(1.0, MIN_ALPHA, N_EPISODES))\n",
    "\n",
    "N_EPISODES = 50\n",
    "MIN_ALPHA = 0.02\n",
    "alphas = generateAlphas(MIN_ALPHA, N_EPISODES)\n",
    "\n",
    "# Ranges of k (this is based for previous experience, simulate many times to test previous experiment whether it holds)\n",
    "largest_k_chosen = 15\n",
    "smallest_k_chosen = 4\n",
    "\n",
    "# Store number of steps for each k\n",
    "k_step = [0 for i in range(largest_k_chosen-smallest_k_chosen+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAAFpCAYAAAABXCv2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMgFMGilQ7wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x19470eb1e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Repeat several times to takes the expected value\n",
    "for e in range(1, 2):\n",
    "    # Initialise the environment and the agent\n",
    "    size = 1000 # size of the q_storage \n",
    "    k = 4 # knn parameter, this is just for initialisation, but later will be change below\n",
    "    agent = KNNAgent(size, k)\n",
    "    mountain_car_environment = MountainCarEnvironment(agent)\n",
    "   \n",
    "    for k_param in range(smallest_k_chosen, largest_k_chosen + 1):\n",
    "        # Iterate the process, train the agent (training_iteration episodes)\n",
    "        training_iteration = N_EPISODES\n",
    "        total_step = 0\n",
    "        agent.k = k_param\n",
    "        useless_k = False\n",
    "        for i in range(training_iteration):\n",
    "            step = 0\n",
    "            alpha = alphas[i]\n",
    "            mountain_car_environment.reset()\n",
    "            while (True):\n",
    "                action = agent.selectAction()\n",
    "                next_state = mountain_car_environment.nextState(action)\n",
    "        \n",
    "                # Change agent current state and getting reward\n",
    "                agent.state = next_state\n",
    "                immediate_reward = mountain_car_environment.calculateReward()\n",
    "                step += 1\n",
    "        \n",
    "                # Test for successful learning\n",
    "                if (immediate_reward == MountainCarEnvironment.REWARD_TERMINAL):\n",
    "                    agent.TDUpdate(immediate_reward, alpha)\n",
    "                    total_step += step\n",
    "                    break\n",
    "        \n",
    "                # Update using Q Learning and kNN\n",
    "                agent.TDUpdate(immediate_reward, alpha)\n",
    "            \n",
    "                # Prevent not converge at all or too long to converge\n",
    "                if (step >= 500000):\n",
    "                    useless_k = True\n",
    "                    total_step = sys.maxsize\n",
    "                    break\n",
    "                \n",
    "                if (total_step > 500000):\n",
    "                    useless_k = True\n",
    "                    total_step = sys.maxsize\n",
    "                    break\n",
    "        \n",
    "            if (useless_k):\n",
    "                break\n",
    "    \n",
    "        # After finishing all episodes required, calculate how many step taken during that period\n",
    "        k_step[k_param - smallest_k_chosen] = (k_step[k_param - smallest_k_chosen] * (e-1) + total_step) / e\n",
    "    \n",
    "        # Graph dynamically\n",
    "        clear_output(wait=True)\n",
    "        y = k_step\n",
    "        x = np.arange(4, 4 + len(y))\n",
    "        plt.scatter(x, y)\n",
    "        plt.title(\"Total Steps vs K\", fontsize=16)\n",
    "        plt.xlabel(\"K\")\n",
    "        plt.ylabel(\"Total Steps\")\n",
    "    \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best k which minimise total steps is k = 10.\n"
     ]
    }
   ],
   "source": [
    "print(\"The best k which minimise total steps is k = {}.\".format(k_step.index(min(k_step)) + smallest_k_chosen))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
