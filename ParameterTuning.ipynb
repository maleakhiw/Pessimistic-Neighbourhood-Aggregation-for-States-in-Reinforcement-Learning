{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Tuning for KNN-TD(0)\n",
    "\n",
    "*Author: Maleakhi Agung Wijaya*  \n",
    "*Date Created: 05/01/2018*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mountain Car Environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MountainCarEnvironment:\n",
    "    \"\"\"\n",
    "    Description: Environment for Mountain Car problem, adapted from Sutton and Barto's Introduction to Reinforcement Learning.\n",
    "    Author: Maleakhi Agung Wijaya\n",
    "    \"\"\"\n",
    "    VELOCITY_BOUNDARIES = (-0.07, 0.07)\n",
    "    POSITION_BOUNDARIES = (-1.2, 0.6) \n",
    "    \n",
    "    INITIAL_VELOCITY = 0.0\n",
    "    INITIAL_POSITION = -0.5\n",
    "    \n",
    "    REWARD_STEP = -1\n",
    "    REWARD_TERMINAL = 0\n",
    "   \n",
    "    # Constructor for MountainCarEnvironment\n",
    "    # Input: agent for the MountainCarEnvironment\n",
    "    # Output: MountainCarEnvironment object\n",
    "    def __init__(self, car):\n",
    "        self.car = car\n",
    "        self.reset()\n",
    "        \n",
    "    # Compute next state (feature)\n",
    "    # Output: [new velocity, new position]\n",
    "    def nextState(self, action):\n",
    "        # Get current state (velocity, position) and the action chosen by the agent\n",
    "        velocity = self.car.state[0]\n",
    "        position = self.car.state[1]\n",
    "        \n",
    "        # Calculate the new velocity and new position\n",
    "        velocity += action * 0.001 + math.cos(3*position) * (-0.0025)\n",
    "        # Consider boundary for velocity\n",
    "        if (velocity < MountainCarEnvironment.VELOCITY_BOUNDARIES[0]):\n",
    "            velocity = MountainCarEnvironment.VELOCITY_BOUNDARIES[0]\n",
    "        elif (velocity > MountainCarEnvironment.VELOCITY_BOUNDARIES[1]):\n",
    "            velocity = MountainCarEnvironment.VELOCITY_BOUNDARIES[1]\n",
    "            \n",
    "        position += velocity\n",
    "        # Consider boundary for position\n",
    "        if (position < MountainCarEnvironment.POSITION_BOUNDARIES[0]):\n",
    "            position = MountainCarEnvironment.POSITION_BOUNDARIES[0]\n",
    "            velocity = 0\n",
    "        elif (position > MountainCarEnvironment.POSITION_BOUNDARIES[1]):\n",
    "            position = MountainCarEnvironment.POSITION_BOUNDARIES[1]\n",
    "        \n",
    "        new_state = [velocity, position]\n",
    "        return(new_state)\n",
    "    \n",
    "    # Reset to the initial state   \n",
    "    def reset(self):\n",
    "        self.car.state[0] = MountainCarEnvironment.INITIAL_VELOCITY\n",
    "        self.car.state[1] = MountainCarEnvironment.INITIAL_POSITION\n",
    "        \n",
    "    # Give reward for each of the chosen action, depending on what the next state that the agent end up in\n",
    "    # Output: terminal state = 0, non-terminal state = -1\n",
    "    def calculateReward(self):\n",
    "        # Get current position of the agent\n",
    "        position = self.car.state[1]\n",
    "        \n",
    "        # Determine the reward given\n",
    "        if (position >= MountainCarEnvironment.POSITION_BOUNDARIES[1]):\n",
    "            return(MountainCarEnvironment.REWARD_TERMINAL)\n",
    "        else:\n",
    "            return(MountainCarEnvironment.REWARD_STEP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN-TD Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class KNNAgent:\n",
    "    \"\"\"\n",
    "    Description: Mountain Car problem agent based on kNN-TD(0) algorithm \n",
    "    Author: Maleakhi Agung Wijaya\n",
    "    \"\"\"\n",
    "    INITIAL_VELOCITY = 0.0\n",
    "    INITIAL_POSITION = -0.5\n",
    "    INITIAL_VALUE = -1\n",
    "    \n",
    "    ACTIONS = [-1, 0, 1]\n",
    "    GAMMA = 0.995\n",
    "    EPSILON = 0.05\n",
    "    \n",
    "    INDEX_DISTANCE = 0\n",
    "    INDEX_ORIGINAL = 1\n",
    "    INDEX_WEIGHT = 2\n",
    "    \n",
    "    REWARD_STEP = -1\n",
    "    REWARD_TERMINAL = 0\n",
    "    \n",
    "    # Constructor\n",
    "    # Input: size of the storage for previous Q values, parameters for how many neighbours which the agent will choose\n",
    "    def __init__(self, size, k):\n",
    "        self.state = [KNNAgent.INITIAL_VELOCITY, KNNAgent.INITIAL_POSITION]\n",
    "        self.q_storage = []\n",
    "        self.k = k # fixed number of nearest neighbours that we will used\n",
    "        self.alpha = 1 # will be decaying and change later\n",
    "        \n",
    "        # Storage of the k nearest neighbour (data) and weight (inverse of distance) for a particular step\n",
    "        self.knn = []\n",
    "        self.weight = []\n",
    "        \n",
    "        # Initialise the storage with random point \n",
    "        for i in range(size):\n",
    "            initial_action = random.randint(-1, 1)\n",
    "            initial_state = [random.uniform(-0.07, 0.07), random.uniform(-1.2, 0.6)]\n",
    "            \n",
    "            # Each data on the array will consist of state, action pair + value\n",
    "            data = {\"state\": initial_state, \"value\": KNNAgent.INITIAL_VALUE, \"action\": initial_action}\n",
    "            self.q_storage.append(data)\n",
    "    \n",
    "    # Find all index for a given value\n",
    "    # Input: value, list to search\n",
    "    # Output: list of all index where you find that value on the list\n",
    "    def findAllIndex(self, value, list_value):\n",
    "        indices = []\n",
    "        for i in range(len(list_value)):\n",
    "              if (value == list_value[i]):\n",
    "                    indices.append(i)\n",
    "        \n",
    "        return indices\n",
    "    \n",
    "    # Standardise feature vector given\n",
    "    # Input: feature vector to be standardised\n",
    "    # Output: standardised feature vector\n",
    "    def standardiseState(self, state):\n",
    "        standardised_state = []\n",
    "        \n",
    "        # The number is taken from VELOCITY_BOUNDARIES and POSITION_BOUNDARIES using normal standardisation formula\n",
    "        standardised_velocity = 2 * ((state[0]+0.07) / (0.07+0.07)) - 1\n",
    "        standardised_position = 2 * ((state[1]+1.2) / (0.6+1.2)) - 1\n",
    "        \n",
    "        standardised_state.append(standardised_velocity)\n",
    "        standardised_state.append(standardised_position)\n",
    "        \n",
    "        return(standardised_state)\n",
    "    \n",
    "    # Calculate Euclidean distance between 2 vectors\n",
    "    # Input: 2 feature vectors\n",
    "    # Output: distance between them\n",
    "    def calculateDistance(self, vector1, vector2):\n",
    "        return(math.sqrt((vector1[0]-vector2[0])**2 + (vector1[1]-vector2[1])**2))\n",
    "    \n",
    "    # Calculate total weight\n",
    "    # Input: list of weights\n",
    "    # Output: total weight\n",
    "    def calculateTotalWeight(self, weight_list):\n",
    "        total_weight = 0\n",
    "        for i in range(len(weight_list)):\n",
    "            total_weight += weight_list[i][KNNAgent.INDEX_WEIGHT]\n",
    "        \n",
    "        return(total_weight)\n",
    "    \n",
    "    # Apply the kNN algorithm for feature vector and store the data point on the neighbours array\n",
    "    # Input: feature vector of current state, actions array consisting of all possible actions, list that will store knn data and weights data\n",
    "    # Output: vector containing the value of taking each action (left, neutral, right)\n",
    "    def kNNTD(self, state, actions, knn_list, weight_list):\n",
    "        approximate_action = []\n",
    "        \n",
    "        # Get the standardised version of state\n",
    "        standardised_state = self.standardiseState(state)\n",
    "        \n",
    "        # Loop through every element in the storage array and only calculate for particular action\n",
    "        for action in actions:\n",
    "            temp = [] # array consisting of tuple (distance, original index, weight) for each point in the q_storage\n",
    "            for i in range(len(self.q_storage)):\n",
    "                data = self.q_storage[i]\n",
    "                # Only want to calculate the nearest neighbour state which has the same action\n",
    "                if (data[\"action\"] == action):\n",
    "                    vector_2 = data[\"state\"]\n",
    "                    standardised_vector_2 = self.standardiseState(vector_2)\n",
    "                    distance = self.calculateDistance(standardised_state, standardised_vector_2)\n",
    "                    index = i\n",
    "                    weight = 1 / (1+distance**2) # weight formula\n",
    "            \n",
    "                    # Create the tuple and append that to temp\n",
    "                    temp.append(tuple((distance, index, weight)))\n",
    "                else:\n",
    "                    continue\n",
    "        \n",
    "            # After we finish looping through all of the point and calculating the standardise distance,\n",
    "            # Sort the tuple based on the distance and only take k of it and append that to the neighbours array\n",
    "            # We also need to calculate the total weight to make it into valid probability that we can compute it's expectation\n",
    "            sorted_temp = sorted(temp, key=lambda x: x[0])\n",
    "            for i in range(self.k):\n",
    "                try:\n",
    "                    weight_list.append(sorted_temp[i])\n",
    "                    knn_list.append(self.q_storage[sorted_temp[i][KNNAgent.INDEX_ORIGINAL]])\n",
    "                except IndexError:\n",
    "                    sys.exit(0)\n",
    "            \n",
    "            # Calculate the expected value of the action and append it to the approximate_action array\n",
    "            expected_value = 0\n",
    "            total_weight = self.calculateTotalWeight(weight_list[(action+1)*self.k:(action+1)*self.k + self.k])\n",
    "            for i in range((action+1)*self.k, (action+1)*self.k + self.k):\n",
    "                weight = weight_list[i][KNNAgent.INDEX_WEIGHT]\n",
    "                probability = weight / total_weight\n",
    "                expected_value += probability * knn_list[i][\"value\"]\n",
    "                \n",
    "            approximate_action.append(expected_value)\n",
    "        \n",
    "        return(approximate_action)\n",
    "    \n",
    "    # Select which action to choose, whether left, neutral, or right (using epsilon greedy)\n",
    "    # Output: -1 (left), 0 (neutral), 1 (right)\n",
    "    def selectAction(self):\n",
    "        # First call the knn-td algorithm to determine the value of each Q(s,a) pairs\n",
    "        action_value = self.kNNTD(self.state, KNNAgent.ACTIONS, self.knn, self.weight)\n",
    "        \n",
    "        # Use the epsilon-greedy method to choose value\n",
    "        random_number = random.uniform(0.0, 1.0)\n",
    "        if (random_number <= KNNAgent.EPSILON):\n",
    "            action_chosen = random.randint(-1, 1)\n",
    "        else:\n",
    "            # Return the action with highest Q(s,a)\n",
    "            possible_index = self.findAllIndex(max(action_value), action_value)\n",
    "            action_chosen = possible_index[random.randrange(len(possible_index))] - 1\n",
    "        \n",
    "        # Only store chosen data in the knn and weight list\n",
    "        # Clearance step\n",
    "        chosen_knn = []\n",
    "        chosen_weight = []\n",
    "        for i in range(self.k*(action_chosen+1), self.k*(action_chosen+1) + self.k):\n",
    "            chosen_knn.append(self.knn[i])\n",
    "            chosen_weight.append(self.weight[i])\n",
    "        self.knn = chosen_knn\n",
    "        self.weight = chosen_weight\n",
    "\n",
    "        return action_chosen\n",
    "    \n",
    "    # Calculate TD target based on Q Learning/ SARSAMAX\n",
    "    # Input: Immediate reward based on what the environment gave\n",
    "    # Output: TD target based on off policy Q learning\n",
    "    def calculateTDTarget(self, immediate_reward):\n",
    "        # Consider condition on the final state, return 0 immediately\n",
    "        if (immediate_reward == KNNAgent.REWARD_TERMINAL):\n",
    "            return(immediate_reward)\n",
    "        \n",
    "        knn_prime = []\n",
    "        weight_prime = []\n",
    "        action_value = self.kNNTD(self.state, KNNAgent.ACTIONS, knn_prime, weight_prime)\n",
    "        \n",
    "        return(immediate_reward + KNNAgent.GAMMA*max(action_value))\n",
    "    \n",
    "    # Q learning TD updates on every neighbours on the kNN based on the contribution that are calculated using probability weight\n",
    "    # Input: Immediate reward based on what the environment gave\n",
    "    def TDUpdate(self, immediate_reward, alpha):\n",
    "        self.alpha = alpha\n",
    "        # First, calculate the TD target\n",
    "        td_target = self.calculateTDTarget(immediate_reward)\n",
    "        \n",
    "        # Iterate every kNN and update using Q learning method based on the weighting\n",
    "        total_weight = self.calculateTotalWeight(self.weight)\n",
    "        for i in range(len(self.weight)):\n",
    "            index = self.weight[i][KNNAgent.INDEX_ORIGINAL]\n",
    "            probability = self.weight[i][KNNAgent.INDEX_WEIGHT] / total_weight\n",
    "            \n",
    "            # Begin updating\n",
    "            td_error = td_target - self.q_storage[index][\"value\"]\n",
    "            self.q_storage[index][\"value\"] = self.q_storage[index][\"value\"] + self.alpha*td_error*probability\n",
    "        \n",
    "        self.cleanList() # clean list to prepare for another step\n",
    "            \n",
    "    # Clear the knn list and also the weight list\n",
    "    def cleanList(self):\n",
    "        self.knn = []\n",
    "        self.weight = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main purpose of this program is to tune the best k parameter/ number of nearest neighbours to use for the  KNN-TD approach described and implemented on [PNA.ipynb](https://github.com/maleakhiw/Pessimistic-Neighbourhood-Aggregation-for-States-in-Reinforcement-Learning/blob/master/PNA.ipynb). The main approach that is used for this purpose is by trying k (number of nearest neighbours) starting from 4 up to considering all points as neighbours. From there, results are generated and inspected for each k which we will choose the best k leading to convergence. The environment that will be used is Mountain Car."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate decaying alphas\n",
    "# Input: minimum alpha, number of episodes\n",
    "# Output: list containing alpha\n",
    "def generateAlphas(minimum_alpha, n_episodes):\n",
    "    return(np.linspace(1.0, MIN_ALPHA, N_EPISODES))\n",
    "\n",
    "N_EPISODES = 50\n",
    "MIN_ALPHA = 0.02\n",
    "alphas = generateAlphas(MIN_ALPHA, N_EPISODES)\n",
    "\n",
    "# Initialise the environment and the agent\n",
    "size = 1000 # size of the q_storage \n",
    "k = 4 # knn parameter, this is just for initialisation, but later will be change below\n",
    "agent = KNNAgent(size, k)\n",
    "mountain_car_environment = MountainCarEnvironment(agent)\n",
    "\n",
    "# Ranges of k (this is based for previous experience, simulate many times to test previous experiment whether it holds)\n",
    "largest_k_chosen = 20\n",
    "smallest_k_chosen = 4\n",
    "\n",
    "# Store initial q storage\n",
    "initial_q_storage = agent.q_storage\n",
    "\n",
    "# Store number of steps for each k\n",
    "k_step = [0 for i in range(20-4+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAf0AAAFpCAYAAACWO/HdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x176d01d4e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for e in range(1, 10):\n",
    "    for k_param in range(smallest_k_chosen, largest_k_chosen + 1):\n",
    "        # Iterate the process, train the agent (training_iteration episodes)\n",
    "        training_iteration = N_EPISODES\n",
    "        total_step = 0\n",
    "        agent.k = k_param\n",
    "        agent.q_storage = initial_q_storage\n",
    "        useless_k = False\n",
    "        for i in range(training_iteration):\n",
    "            step = 0\n",
    "            alpha = alphas[i]\n",
    "            mountain_car_environment.reset()\n",
    "            while (True):\n",
    "                action = agent.selectAction()\n",
    "                next_state = mountain_car_environment.nextState(action)\n",
    "        \n",
    "                # Change agent current state and getting reward\n",
    "                agent.state = next_state\n",
    "                immediate_reward = mountain_car_environment.calculateReward()\n",
    "                step += 1\n",
    "        \n",
    "                # Test for successful learning\n",
    "                if (immediate_reward == MountainCarEnvironment.REWARD_TERMINAL):\n",
    "                    agent.TDUpdate(immediate_reward, alpha)\n",
    "                    total_step += step\n",
    "                    break\n",
    "        \n",
    "                # Update using Q Learning and kNN\n",
    "                agent.TDUpdate(immediate_reward, alpha)\n",
    "            \n",
    "                # Prevent not converge at all or too long to converge\n",
    "                if (step >= 500000):\n",
    "                    useless_k = True\n",
    "                    total_step = sys.maxsize\n",
    "                    break\n",
    "                \n",
    "                if (total_step > 500000):\n",
    "                    useless_k = True\n",
    "                    total_step = sys.maxsize\n",
    "                    break\n",
    "        \n",
    "            if (useless_k):\n",
    "                break\n",
    "    \n",
    "        # After finishing all episodes required, calculate how many step taken during that period\n",
    "        k_step[k_param - smallest_k_chosen] = (k_step[k_param - smallest_k_chosen] + total_step) / e\n",
    "    \n",
    "        # Graph dynamically\n",
    "        clear_output(wait=True)\n",
    "        y = k_step\n",
    "        x = np.arange(4, 4 + len(y))\n",
    "        plt.scatter(x, y)\n",
    "        plt.title(\"Total Steps vs K\", fontsize=16)\n",
    "        plt.xlabel(\"K\")\n",
    "        plt.ylabel(\"Total Steps\")\n",
    "    \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"The best k which minimise total steps is k = {}.\".format(knn_step.index(min(k_step)) + smallest_k_chosen)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
