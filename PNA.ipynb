{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pessimistic Neighbourhood Aggregation for States in Reinforcement Learning\n",
    "\n",
    "Author: Maleakhi Agung Wijaya  \n",
    "Supervisor: Marcus Hutter, Sultan Javed Majeed  \n",
    "Date Created: 21/12/2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mountain Car Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "class MountainCarEnvironment:\n",
    "    '''Implementation of Sutton & Barto (1998) Mountain Car Problem environment.'''\n",
    "    velocity_boundaries = (-0.07, 0.07)\n",
    "    position_boundaries = (-1.2, 0.6)  \n",
    "   \n",
    "    # Constructor for MountainCarEnvironment\n",
    "    # Input: agent for the MountainCarEnvironment\n",
    "    # Output: MountainCarEnvironment object\n",
    "    def __init__(self, car):\n",
    "        self.car = car\n",
    "        self.reset()\n",
    "        \n",
    "    # Compute next state (feature)\n",
    "    # Output: (new velocity, new position)\n",
    "    def nextState(self):\n",
    "        # Get current state (velocity, position) and the action chosen by the agent\n",
    "        velocity = self.car.state[0]\n",
    "        position = self.car.state[1]\n",
    "        action = self.car.doAction()\n",
    "        \n",
    "        # Calculate the new velocity and new position\n",
    "        velocity += action * 0.001 + math.cos(3*position) * -0.0025\n",
    "        position += + velocity\n",
    "        \n",
    "        new_state = (velocity, position)\n",
    "        return(new_state)\n",
    "    \n",
    "    # Reset to the initial state    \n",
    "    def reset(self):\n",
    "        self.car.state[0] = 0.0\n",
    "        self.car.state[1] = -0.5\n",
    "        \n",
    "    # Give reward for each of the chosen action, depending on what the next state that the agent end up in\n",
    "    # Output: terminal state = 0, non-terminal state = -1\n",
    "    def calculateReward(self):\n",
    "        # Get current position of the agent\n",
    "        position = self.car.state[1]\n",
    "        \n",
    "        # Determine the reward given\n",
    "        if (position >= 0.6):\n",
    "            return(0)\n",
    "        else:\n",
    "            return(-1)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Car Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    '''Implementation of agent (car) that will be used in the Mountain Car Environment'''\n",
    "    initial_velocity = 0.0\n",
    "    initial_position = -0.5\n",
    "    \n",
    "    # Constructor\n",
    "    # Input: algorithm (class of algorithm that are used as the based method for our agent)\n",
    "    def __init__(self, algorithm):\n",
    "        self.state = [initial_velocity, initial_position]\n",
    "        self.algorithm = algorithm\n",
    "    \n",
    "    # Allow car to choose action\n",
    "    # Output: -1 (left), 0 (neutral), 1 (right)\n",
    "    def doAction(self):\n",
    "        # TODO: epsilon greedy method for choosing action. For now, just always choose right\n",
    "        return(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kNN-TD Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "class KNN:\n",
    "    '''kNN TD algorithm approach for reinforcement learning.\n",
    "       Theory based on Jose Antonio Martin H., Javier de Lope, and Dario Maravall (The kNN-TD Reinforcement Learning Algorithm)\n",
    "       with some modification. '''\n",
    "    \n",
    "    # Constructor\n",
    "    # Input: the number of k-neighbours, size of the stored Q value\n",
    "    def __init__(self, k, size):\n",
    "        self.k = k # how many neighbours\n",
    "        self.q_storage = [] # storage of the previous q values\n",
    "        \n",
    "        # Initialise the storage with random point \n",
    "        for i in range(size):\n",
    "            initial_value = 0\n",
    "            initial_state = [random.uniform(-0.07, 0.07), random.uniform(-1.2, 0.6)]\n",
    "            \n",
    "            # Each data on the array will consist of state, action pair + value\n",
    "            data = {\"state\": initial_state, \"value\": initial_value, \"action\": initial_action}\n",
    "            self.q_storage.append(data)\n",
    "    \n",
    "    # Stardise feature vector given\n",
    "    # Input: feature vector to be standardised\n",
    "    # Output: standardised feature vector\n",
    "    def standardiseState(self, state):\n",
    "        standardised_state = []\n",
    "        standardised_velocity = 2 * ((state[0]+0.07) / (0.07+0.07)) - 1\n",
    "        standardised_position = 2 * ((state[1]+1.2) / (0.6+1.2)) - 1\n",
    "        standardised_state.append(standardised_velocity)\n",
    "        standardised_state.append(standardised_position)\n",
    "        \n",
    "        return(standardised_state)\n",
    "    \n",
    "    # Calculate Euclidean distance between 2 standardised feature vectors\n",
    "    # Input: 2 feature vectors\n",
    "    # Output: distance between them\n",
    "    def calculateDistance(self, vector1, vector2):\n",
    "        return(math.sqrt((vector1[0]-vector2[0])**2 + (vector1[1]-vector2[1])**2))\n",
    "    \n",
    "    # Apply the kNN algorithm for feature vector and store the data point on the neighbours array\n",
    "    # Input: feature vector of current state\n",
    "    def kNN_TD(self, state):\n",
    "        # Calculate k neighbour for the current state and put the value into neighbours and calculate the weight for each\n",
    "        temp = [] # array  consisting of tuple (distance, original index, weight)\n",
    "        neighbours = []\n",
    "        value_neighbours = [] # array that are used to compute approximation of q value\n",
    "        \n",
    "        # Get the standardised version of state\n",
    "        standardised_state = stardiseState(state)\n",
    "        \n",
    "        # Loop through every element in the storage array\n",
    "        for i in range(len(q_storage)):\n",
    "            data = q_storage[i]\n",
    "            vector_2 = data[\"state\"]\n",
    "            distance = calculateDistance(standardised_state, vector_2)\n",
    "            index = i\n",
    "            weight = 1 / (1 + distance**2)\n",
    "            \n",
    "            # Create the tuple and append that to temp\n",
    "            temp.append(tuple((distance, index, weight)))\n",
    "        \n",
    "        # After we finish looping through all of the point and calculating the standardise distance,\n",
    "        # Sort the tuple based on the distance and only take k of it and append that to the neighbours array\n",
    "        sorted_temp = sorted(temp, key=lambda x: x[0])\n",
    "        for i in range(self.k):\n",
    "            neighbours.append(sorted_temp[i]) # now the neighbours array consist of k closest neighbour\n",
    "            value_neighbours.append(q_storage[sorted_temp[i][1]]) # Get the real data using the original index that we have save\n",
    "            \n",
    "        # As we have the neighbours (containing weight) and also value_neighbour (containing values), we can compute an estimate\n",
    "        # of t+1 state, action pair\n",
    "            \n",
    "            \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
