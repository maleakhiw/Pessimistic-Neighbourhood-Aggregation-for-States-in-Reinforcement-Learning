{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Tuning for KNN-TD(0)\n",
    "\n",
    "*Author: Maleakhi Agung Wijaya*  \n",
    "*Date Created: 05/01/2018*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mountain Car Environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MountainCarEnvironment:\n",
    "    \"\"\"\n",
    "    Description: Environment for Mountain Car problem, adapted from Sutton and Barto's Introduction to Reinforcement Learning.\n",
    "    Author: Maleakhi Agung Wijaya\n",
    "    \"\"\"\n",
    "    VELOCITY_BOUNDARIES = (-0.07, 0.07)\n",
    "    POSITION_BOUNDARIES = (-1.2, 0.6) \n",
    "    \n",
    "    INITIAL_VELOCITY = 0.0\n",
    "    INITIAL_POSITION = -0.5\n",
    "    \n",
    "    REWARD_STEP = -1\n",
    "    REWARD_TERMINAL = 0\n",
    "   \n",
    "    # Constructor for MountainCarEnvironment\n",
    "    # Input: agent for the MountainCarEnvironment\n",
    "    # Output: MountainCarEnvironment object\n",
    "    def __init__(self, car):\n",
    "        self.car = car\n",
    "        self.reset()\n",
    "        \n",
    "    # Compute next state (feature)\n",
    "    # Output: [new velocity, new position]\n",
    "    def nextState(self, action):\n",
    "        # Get current state (velocity, position) and the action chosen by the agent\n",
    "        velocity = self.car.state[0]\n",
    "        position = self.car.state[1]\n",
    "        \n",
    "        # Calculate the new velocity and new position\n",
    "        velocity += action * 0.001 + math.cos(3*position) * (-0.0025)\n",
    "        # Consider boundary for velocity\n",
    "        if (velocity < MountainCarEnvironment.VELOCITY_BOUNDARIES[0]):\n",
    "            velocity = MountainCarEnvironment.VELOCITY_BOUNDARIES[0]\n",
    "        elif (velocity > MountainCarEnvironment.VELOCITY_BOUNDARIES[1]):\n",
    "            velocity = MountainCarEnvironment.VELOCITY_BOUNDARIES[1]\n",
    "            \n",
    "        position += velocity\n",
    "        # Consider boundary for position\n",
    "        if (position < MountainCarEnvironment.POSITION_BOUNDARIES[0]):\n",
    "            position = MountainCarEnvironment.POSITION_BOUNDARIES[0]\n",
    "            velocity = 0\n",
    "        elif (position > MountainCarEnvironment.POSITION_BOUNDARIES[1]):\n",
    "            position = MountainCarEnvironment.POSITION_BOUNDARIES[1]\n",
    "        \n",
    "        new_state = [velocity, position]\n",
    "        return(new_state)\n",
    "    \n",
    "    # Reset to the initial state   \n",
    "    def reset(self):\n",
    "        self.car.state[0] = MountainCarEnvironment.INITIAL_VELOCITY\n",
    "        self.car.state[1] = MountainCarEnvironment.INITIAL_POSITION\n",
    "        \n",
    "    # Give reward for each of the chosen action, depending on what the next state that the agent end up in\n",
    "    # Output: terminal state = 0, non-terminal state = -1\n",
    "    def calculateReward(self):\n",
    "        # Get current position of the agent\n",
    "        position = self.car.state[1]\n",
    "        \n",
    "        # Determine the reward given\n",
    "        if (position >= MountainCarEnvironment.POSITION_BOUNDARIES[1]):\n",
    "            return(MountainCarEnvironment.REWARD_TERMINAL)\n",
    "        else:\n",
    "            return(MountainCarEnvironment.REWARD_STEP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN-TD Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class KNNAgent:\n",
    "    \"\"\"\n",
    "    Description: Mountain Car problem agent based on kNN-TD(0) algorithm \n",
    "    Author: Maleakhi Agung Wijaya\n",
    "    \"\"\"\n",
    "    INITIAL_VELOCITY = 0.0\n",
    "    INITIAL_POSITION = -0.5\n",
    "    INITIAL_VALUE = -1\n",
    "    \n",
    "    ACTIONS = [-1, 0, 1]\n",
    "    GAMMA = 0.995\n",
    "    EPSILON = 0.05\n",
    "    \n",
    "    INDEX_DISTANCE = 0\n",
    "    INDEX_ORIGINAL = 1\n",
    "    INDEX_WEIGHT = 2\n",
    "    \n",
    "    REWARD_STEP = -1\n",
    "    REWARD_TERMINAL = 0\n",
    "    \n",
    "    # Constructor\n",
    "    # Input: size of the storage for previous Q values, parameters for how many neighbours which the agent will choose\n",
    "    def __init__(self, size, k):\n",
    "        self.state = [KNNAgent.INITIAL_VELOCITY, KNNAgent.INITIAL_POSITION]\n",
    "        self.q_storage = []\n",
    "        self.k = k # fixed number of nearest neighbours that we will used\n",
    "        self.alpha = 1 # will be decaying and change later\n",
    "        \n",
    "        # Storage of the k nearest neighbour (data) and weight (inverse of distance) for a particular step\n",
    "        self.knn = []\n",
    "        self.weight = []\n",
    "        \n",
    "        # Initialise the storage with random point \n",
    "        for i in range(size):\n",
    "            initial_action = random.randint(-1, 1)\n",
    "            initial_state = [random.uniform(-0.07, 0.07), random.uniform(-1.2, 0.6)]\n",
    "            \n",
    "            # Each data on the array will consist of state, action pair + value\n",
    "            data = {\"state\": initial_state, \"value\": KNNAgent.INITIAL_VALUE, \"action\": initial_action}\n",
    "            self.q_storage.append(data)\n",
    "    \n",
    "    # Find all index for a given value\n",
    "    # Input: value, list to search\n",
    "    # Output: list of all index where you find that value on the list\n",
    "    def findAllIndex(self, value, list_value):\n",
    "        indices = []\n",
    "        for i in range(len(list_value)):\n",
    "              if (value == list_value[i]):\n",
    "                    indices.append(i)\n",
    "        \n",
    "        return indices\n",
    "    \n",
    "    # Standardise feature vector given\n",
    "    # Input: feature vector to be standardised\n",
    "    # Output: standardised feature vector\n",
    "    def standardiseState(self, state):\n",
    "        standardised_state = []\n",
    "        \n",
    "        # The number is taken from VELOCITY_BOUNDARIES and POSITION_BOUNDARIES using normal standardisation formula\n",
    "        standardised_velocity = 2 * ((state[0]+0.07) / (0.07+0.07)) - 1\n",
    "        standardised_position = 2 * ((state[1]+1.2) / (0.6+1.2)) - 1\n",
    "        \n",
    "        standardised_state.append(standardised_velocity)\n",
    "        standardised_state.append(standardised_position)\n",
    "        \n",
    "        return(standardised_state)\n",
    "    \n",
    "    # Calculate Euclidean distance between 2 vectors\n",
    "    # Input: 2 feature vectors\n",
    "    # Output: distance between them\n",
    "    def calculateDistance(self, vector1, vector2):\n",
    "        return(math.sqrt((vector1[0]-vector2[0])**2 + (vector1[1]-vector2[1])**2))\n",
    "    \n",
    "    # Calculate total weight\n",
    "    # Input: list of weights\n",
    "    # Output: total weight\n",
    "    def calculateTotalWeight(self, weight_list):\n",
    "        total_weight = 0\n",
    "        for i in range(len(weight_list)):\n",
    "            total_weight += weight_list[i][KNNAgent.INDEX_WEIGHT]\n",
    "        \n",
    "        return(total_weight)\n",
    "    \n",
    "    # Apply the kNN algorithm for feature vector and store the data point on the neighbours array\n",
    "    # Input: feature vector of current state, actions array consisting of all possible actions, list that will store knn data and weights data\n",
    "    # Output: vector containing the value of taking each action (left, neutral, right)\n",
    "    def kNNTD(self, state, actions, knn_list, weight_list):\n",
    "        approximate_action = []\n",
    "        \n",
    "        # Get the standardised version of state\n",
    "        standardised_state = self.standardiseState(state)\n",
    "        \n",
    "        # Loop through every element in the storage array and only calculate for particular action\n",
    "        for action in actions:\n",
    "            temp = [] # array consisting of tuple (distance, original index, weight) for each point in the q_storage\n",
    "            for i in range(len(self.q_storage)):\n",
    "                data = self.q_storage[i]\n",
    "                # Only want to calculate the nearest neighbour state which has the same action\n",
    "                if (data[\"action\"] == action):\n",
    "                    vector_2 = data[\"state\"]\n",
    "                    standardised_vector_2 = self.standardiseState(vector_2)\n",
    "                    distance = self.calculateDistance(standardised_state, standardised_vector_2)\n",
    "                    index = i\n",
    "                    weight = 1 / (1+distance**2) # weight formula\n",
    "            \n",
    "                    # Create the tuple and append that to temp\n",
    "                    temp.append(tuple((distance, index, weight)))\n",
    "                else:\n",
    "                    continue\n",
    "        \n",
    "            # After we finish looping through all of the point and calculating the standardise distance,\n",
    "            # Sort the tuple based on the distance and only take k of it and append that to the neighbours array\n",
    "            # We also need to calculate the total weight to make it into valid probability that we can compute it's expectation\n",
    "            sorted_temp = sorted(temp, key=lambda x: x[0])\n",
    "            for i in range(self.k):\n",
    "                try:\n",
    "                    weight_list.append(sorted_temp[i])\n",
    "                    knn_list.append(self.q_storage[sorted_temp[i][KNNAgent.INDEX_ORIGINAL]])\n",
    "                except IndexError:\n",
    "                    sys.exit(0)\n",
    "            \n",
    "            # Calculate the expected value of the action and append it to the approximate_action array\n",
    "            expected_value = 0\n",
    "            total_weight = self.calculateTotalWeight(weight_list[(action+1)*self.k:(action+1)*self.k + self.k])\n",
    "            for i in range((action+1)*self.k, (action+1)*self.k + self.k):\n",
    "                weight = weight_list[i][KNNAgent.INDEX_WEIGHT]\n",
    "                probability = weight / total_weight\n",
    "                expected_value += probability * knn_list[i][\"value\"]\n",
    "                \n",
    "            approximate_action.append(expected_value)\n",
    "        \n",
    "        return(approximate_action)\n",
    "    \n",
    "    # Select which action to choose, whether left, neutral, or right (using epsilon greedy)\n",
    "    # Output: -1 (left), 0 (neutral), 1 (right)\n",
    "    def selectAction(self):\n",
    "        # First call the knn-td algorithm to determine the value of each Q(s,a) pairs\n",
    "        action_value = self.kNNTD(self.state, KNNAgent.ACTIONS, self.knn, self.weight)\n",
    "        \n",
    "        # Use the epsilon-greedy method to choose value\n",
    "        random_number = random.uniform(0.0, 1.0)\n",
    "        if (random_number <= KNNAgent.EPSILON):\n",
    "            action_chosen = random.randint(-1, 1)\n",
    "        else:\n",
    "            # Return the action with highest Q(s,a)\n",
    "            possible_index = self.findAllIndex(max(action_value), action_value)\n",
    "            action_chosen = possible_index[random.randrange(len(possible_index))] - 1\n",
    "        \n",
    "        # Only store chosen data in the knn and weight list\n",
    "        # Clearance step\n",
    "        chosen_knn = []\n",
    "        chosen_weight = []\n",
    "        for i in range(self.k*(action_chosen+1), self.k*(action_chosen+1) + self.k):\n",
    "            chosen_knn.append(self.knn[i])\n",
    "            chosen_weight.append(self.weight[i])\n",
    "        self.knn = chosen_knn\n",
    "        self.weight = chosen_weight\n",
    "\n",
    "        return action_chosen\n",
    "    \n",
    "    # Calculate TD target based on Q Learning/ SARSAMAX\n",
    "    # Input: Immediate reward based on what the environment gave\n",
    "    # Output: TD target based on off policy Q learning\n",
    "    def calculateTDTarget(self, immediate_reward):\n",
    "        # Consider condition on the final state, return 0 immediately\n",
    "        if (immediate_reward == KNNAgent.REWARD_TERMINAL):\n",
    "            return(immediate_reward)\n",
    "        \n",
    "        knn_prime = []\n",
    "        weight_prime = []\n",
    "        action_value = self.kNNTD(self.state, KNNAgent.ACTIONS, knn_prime, weight_prime)\n",
    "        \n",
    "        return(immediate_reward + KNNAgent.GAMMA*max(action_value))\n",
    "    \n",
    "    # Q learning TD updates on every neighbours on the kNN based on the contribution that are calculated using probability weight\n",
    "    # Input: Immediate reward based on what the environment gave\n",
    "    def TDUpdate(self, immediate_reward, alpha):\n",
    "        self.alpha = alpha\n",
    "        # First, calculate the TD target\n",
    "        td_target = self.calculateTDTarget(immediate_reward)\n",
    "        \n",
    "        # Iterate every kNN and update using Q learning method based on the weighting\n",
    "        total_weight = self.calculateTotalWeight(self.weight)\n",
    "        for i in range(len(self.weight)):\n",
    "            index = self.weight[i][KNNAgent.INDEX_ORIGINAL]\n",
    "            probability = self.weight[i][KNNAgent.INDEX_WEIGHT] / total_weight\n",
    "            \n",
    "            # Begin updating\n",
    "            td_error = td_target - self.q_storage[index][\"value\"]\n",
    "            self.q_storage[index][\"value\"] = self.q_storage[index][\"value\"] + self.alpha*td_error*probability\n",
    "        \n",
    "        self.cleanList() # clean list to prepare for another step\n",
    "            \n",
    "    # Clear the knn list and also the weight list\n",
    "    def cleanList(self):\n",
    "        self.knn = []\n",
    "        self.weight = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main purpose of this program is to tune the best k parameter/ number of nearest neighbours to use for the  KNN-TD approach described and implemented on [PNA.ipynb](https://github.com/maleakhiw/Pessimistic-Neighbourhood-Aggregation-for-States-in-Reinforcement-Learning/blob/master/PNA.ipynb). The main approach that is used for this purpose is by trying k (number of nearest neighbours) starting from 4 up to considering all points as neighbours. From there, results are generated and inspected for each k which we will choose the best k leading to convergence. The environment that will be used is Mountain Car."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate decaying alphas\n",
    "# Input: minimum alpha, number of episodes\n",
    "# Output: list containing alpha\n",
    "def generateAlphas(minimum_alpha, n_episodes):\n",
    "    return(np.linspace(1.0, MIN_ALPHA, N_EPISODES))\n",
    "\n",
    "N_EPISODES = 50\n",
    "MIN_ALPHA = 0.02\n",
    "alphas = generateAlphas(MIN_ALPHA, N_EPISODES)\n",
    "\n",
    "# Initialise the environment and the agent\n",
    "size = 1000 # size of the q_storage \n",
    "k = 4 # knn parameter, this is just for initialisation, but later will be change below\n",
    "agent = KNNAgent(size, k)\n",
    "mountain_car_environment = MountainCarEnvironment(agent)\n",
    "\n",
    "# Ranges of k (this is based for previous experience, simulate many times to test previous experiment whether it holds)\n",
    "largest_k_chosen = 20\n",
    "smallest_k_chosen = 4\n",
    "\n",
    "# Store initial q storage\n",
    "initial_q_storage = agent.q_storage\n",
    "\n",
    "# Store number of steps for each k\n",
    "k_step = [0 for i in range(20-4+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAf0AAAFpCAYAAACWO/HdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQSj0RUREDOL/AeHurQmcrmc/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f583b224a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for e in range(1, 10):\n",
    "    for k_param in range(smallest_k_chosen, largest_k_chosen + 1):\n",
    "        # Iterate the process, train the agent (training_iteration episodes)\n",
    "        training_iteration = N_EPISODES\n",
    "        total_step = 0\n",
    "        agent.k = k_param\n",
    "        agent.q_storage = initial_q_storage\n",
    "        useless_k = False\n",
    "        for i in range(training_iteration):\n",
    "            step = 0\n",
    "            alpha = alphas[i]\n",
    "            mountain_car_environment.reset()\n",
    "            while (True):\n",
    "                action = agent.selectAction()\n",
    "                next_state = mountain_car_environment.nextState(action)\n",
    "        \n",
    "                # Change agent current state and getting reward\n",
    "                agent.state = next_state\n",
    "                immediate_reward = mountain_car_environment.calculateReward()\n",
    "                step += 1\n",
    "        \n",
    "                # Test for successful learning\n",
    "                if (immediate_reward == MountainCarEnvironment.REWARD_TERMINAL):\n",
    "                    agent.TDUpdate(immediate_reward, alpha)\n",
    "                    total_step += step\n",
    "                    break\n",
    "        \n",
    "                # Update using Q Learning and kNN\n",
    "                agent.TDUpdate(immediate_reward, alpha)\n",
    "            \n",
    "                # Prevent not converge at all or too long to converge\n",
    "                if (step >= 500000):\n",
    "                    useless_k = True\n",
    "                    total_step = sys.maxsize\n",
    "                    break\n",
    "                \n",
    "                if (total_step > 500000):\n",
    "                    useless_k = True\n",
    "                    total_step = sys.maxsize\n",
    "                    break\n",
    "        \n",
    "            if (useless_k):\n",
    "                break\n",
    "    \n",
    "        # After finishing all episodes required, calculate how many step taken during that period\n",
    "        k_step[k_param - smallest_k_chosen] = (k_step[k_param - smallest_k_chosen] + total_step) / e\n",
    "    \n",
    "        # Graph dynamically\n",
    "        clear_output(wait=True)\n",
    "        y = k_step\n",
    "        x = np.arange(4, 4 + len(y))\n",
    "        plt.scatter(x, y)\n",
    "        plt.title(\"Total Steps vs K\", fontsize=16)\n",
    "        plt.xlabel(\"K\")\n",
    "        plt.ylabel(\"Total Steps\")\n",
    "    \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"The best k which minimise total steps is k = {}.\".format(knn_step.index(min(k_step)) + smallest_k_chosen)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
