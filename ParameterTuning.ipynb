{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Tuning for KNN-TD(0)\n",
    "\n",
    "*Author: Maleakhi Agung Wijaya*  \n",
    "*Date Created: 05/01/2018*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mountain Car Environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MountainCarEnvironment:\n",
    "    \"\"\"\n",
    "    Description: Environment for Mountain Car problem, adapted from Sutton and Barto's Introduction to Reinforcement Learning.\n",
    "    Author: Maleakhi Agung Wijaya\n",
    "    \"\"\"\n",
    "    VELOCITY_BOUNDARIES = (-0.07, 0.07)\n",
    "    POSITION_BOUNDARIES = (-1.2, 0.6) \n",
    "    \n",
    "    INITIAL_VELOCITY = 0.0\n",
    "    INITIAL_POSITION = -0.5\n",
    "    \n",
    "    REWARD_STEP = -1\n",
    "    REWARD_TERMINAL = 0\n",
    "   \n",
    "    # Constructor for MountainCarEnvironment\n",
    "    # Input: agent for the MountainCarEnvironment\n",
    "    # Output: MountainCarEnvironment object\n",
    "    def __init__(self, car):\n",
    "        self.car = car\n",
    "        self.reset()\n",
    "        \n",
    "    # Compute next state (feature)\n",
    "    # Output: [new velocity, new position]\n",
    "    def nextState(self, action):\n",
    "        # Get current state (velocity, position) and the action chosen by the agent\n",
    "        velocity = self.car.state[0]\n",
    "        position = self.car.state[1]\n",
    "        \n",
    "        # Calculate the new velocity and new position\n",
    "        velocity += action * 0.001 + math.cos(3*position) * (-0.0025)\n",
    "        # Consider boundary for velocity\n",
    "        if (velocity < MountainCarEnvironment.VELOCITY_BOUNDARIES[0]):\n",
    "            velocity = MountainCarEnvironment.VELOCITY_BOUNDARIES[0]\n",
    "        elif (velocity > MountainCarEnvironment.VELOCITY_BOUNDARIES[1]):\n",
    "            velocity = MountainCarEnvironment.VELOCITY_BOUNDARIES[1]\n",
    "            \n",
    "        position += velocity\n",
    "        # Consider boundary for position\n",
    "        if (position < MountainCarEnvironment.POSITION_BOUNDARIES[0]):\n",
    "            position = MountainCarEnvironment.POSITION_BOUNDARIES[0]\n",
    "            velocity = 0\n",
    "        elif (position > MountainCarEnvironment.POSITION_BOUNDARIES[1]):\n",
    "            position = MountainCarEnvironment.POSITION_BOUNDARIES[1]\n",
    "        \n",
    "        new_state = [velocity, position]\n",
    "        return(new_state)\n",
    "    \n",
    "    # Reset to the initial state   \n",
    "    def reset(self):\n",
    "        self.car.state[0] = MountainCarEnvironment.INITIAL_VELOCITY\n",
    "        self.car.state[1] = MountainCarEnvironment.INITIAL_POSITION\n",
    "        \n",
    "    # Give reward for each of the chosen action, depending on what the next state that the agent end up in\n",
    "    # Output: terminal state = 0, non-terminal state = -1\n",
    "    def calculateReward(self):\n",
    "        # Get current position of the agent\n",
    "        position = self.car.state[1]\n",
    "        \n",
    "        # Determine the reward given\n",
    "        if (position >= MountainCarEnvironment.POSITION_BOUNDARIES[1]):\n",
    "            return(MountainCarEnvironment.REWARD_TERMINAL)\n",
    "        else:\n",
    "            return(MountainCarEnvironment.REWARD_STEP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN-TD Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class KNNAgent:\n",
    "    \"\"\"\n",
    "    Description: Mountain Car problem agent based on kNN-TD(0) algorithm \n",
    "    Author: Maleakhi Agung Wijaya\n",
    "    \"\"\"\n",
    "    INITIAL_VELOCITY = 0.0\n",
    "    INITIAL_POSITION = -0.5\n",
    "    INITIAL_VALUE = -1\n",
    "    \n",
    "    ACTIONS = [-1, 0, 1]\n",
    "    GAMMA = 0.995\n",
    "    EPSILON = 0.05\n",
    "    \n",
    "    INDEX_DISTANCE = 0\n",
    "    INDEX_ORIGINAL = 1\n",
    "    INDEX_WEIGHT = 2\n",
    "    \n",
    "    REWARD_STEP = -1\n",
    "    REWARD_TERMINAL = 0\n",
    "    \n",
    "    # Constructor\n",
    "    # Input: size of the storage for previous Q values, parameters for how many neighbours which the agent will choose\n",
    "    def __init__(self, size, k):\n",
    "        self.state = [KNNAgent.INITIAL_VELOCITY, KNNAgent.INITIAL_POSITION]\n",
    "        self.q_storage = []\n",
    "        self.k = k # fixed number of nearest neighbours that we will used\n",
    "        self.alpha = 1 # will be decaying and change later\n",
    "        \n",
    "        # Storage of the k nearest neighbour (data) and weight (inverse of distance) for a particular step\n",
    "        self.knn = []\n",
    "        self.weight = []\n",
    "        \n",
    "        # Initialise the storage with random point \n",
    "        for i in range(size):\n",
    "            initial_action = random.randint(-1, 1)\n",
    "            initial_state = [random.uniform(-0.07, 0.07), random.uniform(-1.2, 0.6)]\n",
    "            \n",
    "            # Each data on the array will consist of state, action pair + value\n",
    "            data = {\"state\": initial_state, \"value\": KNNAgent.INITIAL_VALUE, \"action\": initial_action}\n",
    "            self.q_storage.append(data)\n",
    "    \n",
    "    # Find all index for a given value\n",
    "    # Input: value, list to search\n",
    "    # Output: list of all index where you find that value on the list\n",
    "    def findAllIndex(self, value, list_value):\n",
    "        indices = []\n",
    "        for i in range(len(list_value)):\n",
    "              if (value == list_value[i]):\n",
    "                    indices.append(i)\n",
    "        \n",
    "        return indices\n",
    "    \n",
    "    # Standardise feature vector given\n",
    "    # Input: feature vector to be standardised\n",
    "    # Output: standardised feature vector\n",
    "    def standardiseState(self, state):\n",
    "        standardised_state = []\n",
    "        \n",
    "        # The number is taken from VELOCITY_BOUNDARIES and POSITION_BOUNDARIES using normal standardisation formula\n",
    "        standardised_velocity = 2 * ((state[0]+0.07) / (0.07+0.07)) - 1\n",
    "        standardised_position = 2 * ((state[1]+1.2) / (0.6+1.2)) - 1\n",
    "        \n",
    "        standardised_state.append(standardised_velocity)\n",
    "        standardised_state.append(standardised_position)\n",
    "        \n",
    "        return(standardised_state)\n",
    "    \n",
    "    # Calculate Euclidean distance between 2 vectors\n",
    "    # Input: 2 feature vectors\n",
    "    # Output: distance between them\n",
    "    def calculateDistance(self, vector1, vector2):\n",
    "        return(math.sqrt((vector1[0]-vector2[0])**2 + (vector1[1]-vector2[1])**2))\n",
    "    \n",
    "    # Calculate total weight\n",
    "    # Input: list of weights\n",
    "    # Output: total weight\n",
    "    def calculateTotalWeight(self, weight_list):\n",
    "        total_weight = 0\n",
    "        for i in range(len(weight_list)):\n",
    "            total_weight += weight_list[i][KNNAgent.INDEX_WEIGHT]\n",
    "        \n",
    "        return(total_weight)\n",
    "    \n",
    "    # Apply the kNN algorithm for feature vector and store the data point on the neighbours array\n",
    "    # Input: feature vector of current state, actions array consisting of all possible actions, list that will store knn data and weights data\n",
    "    # Output: vector containing the value of taking each action (left, neutral, right)\n",
    "    def kNNTD(self, state, actions, knn_list, weight_list):\n",
    "        approximate_action = []\n",
    "        \n",
    "        # Get the standardised version of state\n",
    "        standardised_state = self.standardiseState(state)\n",
    "        \n",
    "        # Loop through every element in the storage array and only calculate for particular action\n",
    "        for action in actions:\n",
    "            temp = [] # array consisting of tuple (distance, original index, weight) for each point in the q_storage\n",
    "            for i in range(len(self.q_storage)):\n",
    "                data = self.q_storage[i]\n",
    "                # Only want to calculate the nearest neighbour state which has the same action\n",
    "                if (data[\"action\"] == action):\n",
    "                    vector_2 = data[\"state\"]\n",
    "                    standardised_vector_2 = self.standardiseState(vector_2)\n",
    "                    distance = self.calculateDistance(standardised_state, standardised_vector_2)\n",
    "                    index = i\n",
    "                    weight = 1 / (1+distance**2) # weight formula\n",
    "            \n",
    "                    # Create the tuple and append that to temp\n",
    "                    temp.append(tuple((distance, index, weight)))\n",
    "                else:\n",
    "                    continue\n",
    "        \n",
    "            # After we finish looping through all of the point and calculating the standardise distance,\n",
    "            # Sort the tuple based on the distance and only take k of it and append that to the neighbours array\n",
    "            # We also need to calculate the total weight to make it into valid probability that we can compute it's expectation\n",
    "            sorted_temp = sorted(temp, key=lambda x: x[0])\n",
    "            for i in range(self.k):\n",
    "                try:\n",
    "                    weight_list.append(sorted_temp[i])\n",
    "                    knn_list.append(self.q_storage[sorted_temp[i][KNNAgent.INDEX_ORIGINAL]])\n",
    "                except IndexError:\n",
    "                    sys.exit(0)\n",
    "            \n",
    "            # Calculate the expected value of the action and append it to the approximate_action array\n",
    "            expected_value = 0\n",
    "            total_weight = self.calculateTotalWeight(weight_list[(action+1)*self.k:(action+1)*self.k + self.k])\n",
    "            for i in range((action+1)*self.k, (action+1)*self.k + self.k):\n",
    "                weight = weight_list[i][KNNAgent.INDEX_WEIGHT]\n",
    "                probability = weight / total_weight\n",
    "                expected_value += probability * knn_list[i][\"value\"]\n",
    "                \n",
    "            approximate_action.append(expected_value)\n",
    "        \n",
    "        return(approximate_action)\n",
    "    \n",
    "    # Select which action to choose, whether left, neutral, or right (using epsilon greedy)\n",
    "    # Output: -1 (left), 0 (neutral), 1 (right)\n",
    "    def selectAction(self):\n",
    "        # First call the knn-td algorithm to determine the value of each Q(s,a) pairs\n",
    "        action_value = self.kNNTD(self.state, KNNAgent.ACTIONS, self.knn, self.weight)\n",
    "        \n",
    "        # Use the epsilon-greedy method to choose value\n",
    "        random_number = random.uniform(0.0, 1.0)\n",
    "        if (random_number <= KNNAgent.EPSILON):\n",
    "            action_chosen = random.randint(-1, 1)\n",
    "        else:\n",
    "            # Return the action with highest Q(s,a)\n",
    "            possible_index = self.findAllIndex(max(action_value), action_value)\n",
    "            action_chosen = possible_index[random.randrange(len(possible_index))] - 1\n",
    "        \n",
    "        # Only store chosen data in the knn and weight list\n",
    "        # Clearance step\n",
    "        chosen_knn = []\n",
    "        chosen_weight = []\n",
    "        for i in range(self.k*(action_chosen+1), self.k*(action_chosen+1) + self.k):\n",
    "            chosen_knn.append(self.knn[i])\n",
    "            chosen_weight.append(self.weight[i])\n",
    "        self.knn = chosen_knn\n",
    "        self.weight = chosen_weight\n",
    "\n",
    "        return action_chosen\n",
    "    \n",
    "    # Calculate TD target based on Q Learning/ SARSAMAX\n",
    "    # Input: Immediate reward based on what the environment gave\n",
    "    # Output: TD target based on off policy Q learning\n",
    "    def calculateTDTarget(self, immediate_reward):\n",
    "        # Consider condition on the final state, return 0 immediately\n",
    "        if (immediate_reward == KNNAgent.REWARD_TERMINAL):\n",
    "            return(immediate_reward)\n",
    "        \n",
    "        knn_prime = []\n",
    "        weight_prime = []\n",
    "        action_value = self.kNNTD(self.state, KNNAgent.ACTIONS, knn_prime, weight_prime)\n",
    "        \n",
    "        return(immediate_reward + KNNAgent.GAMMA*max(action_value))\n",
    "    \n",
    "    # Q learning TD updates on every neighbours on the kNN based on the contribution that are calculated using probability weight\n",
    "    # Input: Immediate reward based on what the environment gave\n",
    "    def TDUpdate(self, immediate_reward, alpha):\n",
    "        self.alpha = alpha\n",
    "        # First, calculate the TD target\n",
    "        td_target = self.calculateTDTarget(immediate_reward)\n",
    "        \n",
    "        # Iterate every kNN and update using Q learning method based on the weighting\n",
    "        total_weight = self.calculateTotalWeight(self.weight)\n",
    "        for i in range(len(self.weight)):\n",
    "            index = self.weight[i][KNNAgent.INDEX_ORIGINAL]\n",
    "            probability = self.weight[i][KNNAgent.INDEX_WEIGHT] / total_weight\n",
    "            \n",
    "            # Begin updating\n",
    "            td_error = td_target - self.q_storage[index][\"value\"]\n",
    "            self.q_storage[index][\"value\"] = self.q_storage[index][\"value\"] + self.alpha*td_error*probability\n",
    "        \n",
    "        self.cleanList() # clean list to prepare for another step\n",
    "            \n",
    "    # Clear the knn list and also the weight list\n",
    "    def cleanList(self):\n",
    "        self.knn = []\n",
    "        self.weight = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main purpose of this program is to tune the best k parameter/ number of nearest neighbours to use for the  KNN-TD approach described and implemented on [PNA.ipynb](https://github.com/maleakhiw/Pessimistic-Neighbourhood-Aggregation-for-States-in-Reinforcement-Learning/blob/master/PNA.ipynb). The main approach that is used for this purpose is by trying k (number of nearest neighbours) starting from 4 up to considering all points as neighbours. From there, results are generated and inspected for each k which we will choose the best k leading to convergence. The environment that will be used is Mountain Car."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate decaying alphas\n",
    "# Input: minimum alpha, number of episodes\n",
    "# Output: list containing alpha\n",
    "def generateAlphas(minimum_alpha, n_episodes):\n",
    "    return(np.linspace(1.0, MIN_ALPHA, N_EPISODES))\n",
    "\n",
    "N_EPISODES = 50\n",
    "MIN_ALPHA = 0.02\n",
    "alphas = generateAlphas(MIN_ALPHA, N_EPISODES)\n",
    "\n",
    "# Initialise the environment and the agent\n",
    "size = 1000 # size of the q_storage \n",
    "k = 4 # knn parameter, this is just for initialisation, but later will be change below\n",
    "agent = KNNAgent(size, k)\n",
    "mountain_car_environment = MountainCarEnvironment(agent)\n",
    "\n",
    "# Ranges of k (this is based for previous experience, simulate many times to test previous experiment whether it holds)\n",
    "largest_k_chosen = 20\n",
    "smallest_k_chosen = 4\n",
    "\n",
    "# Store initial q storage\n",
    "initial_q_storage = agent.q_storage\n",
    "\n",
    "# Store number of steps for each k\n",
    "k_step = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAf0AAAFpCAYAAACWO/HdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2cf3866ca58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for k_param in range(smallest_k_chosen, largest_k_chosen + 1):\n",
    "    # Iterate the process, train the agent (training_iteration episodes)\n",
    "    training_iteration = N_EPISODES\n",
    "    total_step = 0\n",
    "    agent.k = k_param\n",
    "    agent.q_storage = initial_q_storage\n",
    "    useless_k = False\n",
    "    for i in range(training_iteration):\n",
    "        step = 0\n",
    "        alpha = alphas[i]\n",
    "        mountain_car_environment.reset()\n",
    "        while (True):\n",
    "            action = agent.selectAction()\n",
    "            next_state = mountain_car_environment.nextState(action)\n",
    "        \n",
    "            # Change agent current state and getting reward\n",
    "            agent.state = next_state\n",
    "            immediate_reward = mountain_car_environment.calculateReward()\n",
    "            step += 1\n",
    "        \n",
    "            # Test for successful learning\n",
    "            if (immediate_reward == MountainCarEnvironment.REWARD_TERMINAL):\n",
    "                agent.TDUpdate(immediate_reward, alpha)\n",
    "                total_step += step\n",
    "                break\n",
    "        \n",
    "            # Update using Q Learning and kNN\n",
    "            agent.TDUpdate(immediate_reward, alpha)\n",
    "            \n",
    "            # Prevent not converge at all or too long to converge\n",
    "            if (step >= 500000):\n",
    "                useless_k = True\n",
    "                total_step = sys.maxsize\n",
    "                break\n",
    "                \n",
    "            if (total_step > 500000):\n",
    "                useless_k = True\n",
    "                total_step = sys.maxsize\n",
    "                break\n",
    "        \n",
    "        if (useless_k):\n",
    "            break\n",
    "    \n",
    "    # After finishing all episodes required, calculate how many step taken during that period\n",
    "    k_step.append(total_step)\n",
    "    \n",
    "    # Graph dynamically\n",
    "    clear_output(wait=True)\n",
    "    y = k_step\n",
    "    x = np.arange(4, 4 + len(y))\n",
    "    plt.scatter(x, y)\n",
    "    plt.title(\"Total Steps vs K\", fontsize=16)\n",
    "    plt.xlabel(\"K\")\n",
    "    plt.ylabel(\"Total Steps\")\n",
    "    \n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
