{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Tuning for KNN-TD(0)\n",
    "\n",
    "*Author: Maleakhi Agung Wijaya*  \n",
    "*Date Created: 05/01/2018*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mountain Car Environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MountainCarEnvironment:\n",
    "    \"\"\"\n",
    "    Description: Environment for Mountain Car problem, adapted from Sutton and Barto's Introduction to Reinforcement Learning.\n",
    "    Author: Maleakhi Agung Wijaya\n",
    "    \"\"\"\n",
    "    VELOCITY_BOUNDARIES = (-0.07, 0.07)\n",
    "    POSITION_BOUNDARIES = (-1.2, 0.6) \n",
    "    \n",
    "    INITIAL_VELOCITY = 0.0\n",
    "    INITIAL_POSITION = -0.5\n",
    "    \n",
    "    REWARD_STEP = -1\n",
    "    REWARD_TERMINAL = 0\n",
    "   \n",
    "    # Constructor for MountainCarEnvironment\n",
    "    # Input: agent for the MountainCarEnvironment\n",
    "    # Output: MountainCarEnvironment object\n",
    "    def __init__(self, car):\n",
    "        self.car = car\n",
    "        self.reset()\n",
    "        \n",
    "    # Compute next state (feature)\n",
    "    # Output: [new velocity, new position]\n",
    "    def nextState(self, action):\n",
    "        # Get current state (velocity, position) and the action chosen by the agent\n",
    "        velocity = self.car.state[0]\n",
    "        position = self.car.state[1]\n",
    "        \n",
    "        # Calculate the new velocity and new position\n",
    "        velocity += action * 0.001 + math.cos(3*position) * (-0.0025)\n",
    "        # Consider boundary for velocity\n",
    "        if (velocity < MountainCarEnvironment.VELOCITY_BOUNDARIES[0]):\n",
    "            velocity = MountainCarEnvironment.VELOCITY_BOUNDARIES[0]\n",
    "        elif (velocity > MountainCarEnvironment.VELOCITY_BOUNDARIES[1]):\n",
    "            velocity = MountainCarEnvironment.VELOCITY_BOUNDARIES[1]\n",
    "            \n",
    "        position += velocity\n",
    "        # Consider boundary for position\n",
    "        if (position < MountainCarEnvironment.POSITION_BOUNDARIES[0]):\n",
    "            position = MountainCarEnvironment.POSITION_BOUNDARIES[0]\n",
    "            velocity = 0\n",
    "        elif (position > MountainCarEnvironment.POSITION_BOUNDARIES[1]):\n",
    "            position = MountainCarEnvironment.POSITION_BOUNDARIES[1]\n",
    "        \n",
    "        new_state = [velocity, position]\n",
    "        return(new_state)\n",
    "    \n",
    "    # Reset to the initial state   \n",
    "    def reset(self):\n",
    "        self.car.state[0] = MountainCarEnvironment.INITIAL_VELOCITY\n",
    "        self.car.state[1] = MountainCarEnvironment.INITIAL_POSITION\n",
    "        \n",
    "    # Give reward for each of the chosen action, depending on what the next state that the agent end up in\n",
    "    # Output: terminal state = 0, non-terminal state = -1\n",
    "    def calculateReward(self):\n",
    "        # Get current position of the agent\n",
    "        position = self.car.state[1]\n",
    "        \n",
    "        # Determine the reward given\n",
    "        if (position >= MountainCarEnvironment.POSITION_BOUNDARIES[1]):\n",
    "            return(MountainCarEnvironment.REWARD_TERMINAL)\n",
    "        else:\n",
    "            return(MountainCarEnvironment.REWARD_STEP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN-TD Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class KNNAgent:\n",
    "    \"\"\"\n",
    "    Description: Mountain Car problem agent based on kNN-TD(0) algorithm \n",
    "    Author: Maleakhi Agung Wijaya\n",
    "    \"\"\"\n",
    "    INITIAL_VELOCITY = 0.0\n",
    "    INITIAL_POSITION = -0.5\n",
    "    INITIAL_VALUE = -1\n",
    "    \n",
    "    ACTIONS = [-1, 0, 1]\n",
    "    GAMMA = 0.995\n",
    "    EPSILON = 0.05\n",
    "    \n",
    "    INDEX_DISTANCE = 0\n",
    "    INDEX_ORIGINAL = 1\n",
    "    INDEX_WEIGHT = 2\n",
    "    \n",
    "    REWARD_STEP = -1\n",
    "    REWARD_TERMINAL = 0\n",
    "    \n",
    "    # Constructor\n",
    "    # Input: size of the storage for previous Q values, parameters for how many neighbours which the agent will choose\n",
    "    def __init__(self, size, k):\n",
    "        self.state = [KNNAgent.INITIAL_VELOCITY, KNNAgent.INITIAL_POSITION]\n",
    "        self.q_storage = []\n",
    "        self.k = k # fixed number of nearest neighbours that we will used\n",
    "        self.alpha = 1 # will be decaying and change later\n",
    "        \n",
    "        # Storage of the k nearest neighbour (data) and weight (inverse of distance) for a particular step\n",
    "        self.knn = []\n",
    "        self.weight = []\n",
    "        \n",
    "        # Initialise the storage with random point \n",
    "        for i in range(size):\n",
    "            initial_action = random.randint(-1, 1)\n",
    "            initial_state = [random.uniform(-0.07, 0.07), random.uniform(-1.2, 0.6)]\n",
    "            \n",
    "            # Each data on the array will consist of state, action pair + value\n",
    "            data = {\"state\": initial_state, \"value\": KNNAgent.INITIAL_VALUE, \"action\": initial_action}\n",
    "            self.q_storage.append(data)\n",
    "    \n",
    "    # Find all index for a given value\n",
    "    # Input: value, list to search\n",
    "    # Output: list of all index where you find that value on the list\n",
    "    def findAllIndex(self, value, list_value):\n",
    "        indices = []\n",
    "        for i in range(len(list_value)):\n",
    "              if (value == list_value[i]):\n",
    "                    indices.append(i)\n",
    "        \n",
    "        return indices\n",
    "    \n",
    "    # Standardise feature vector given\n",
    "    # Input: feature vector to be standardised\n",
    "    # Output: standardised feature vector\n",
    "    def standardiseState(self, state):\n",
    "        standardised_state = []\n",
    "        \n",
    "        # The number is taken from VELOCITY_BOUNDARIES and POSITION_BOUNDARIES using normal standardisation formula\n",
    "        standardised_velocity = 2 * ((state[0]+0.07) / (0.07+0.07)) - 1\n",
    "        standardised_position = 2 * ((state[1]+1.2) / (0.6+1.2)) - 1\n",
    "        \n",
    "        standardised_state.append(standardised_velocity)\n",
    "        standardised_state.append(standardised_position)\n",
    "        \n",
    "        return(standardised_state)\n",
    "    \n",
    "    # Calculate Euclidean distance between 2 vectors\n",
    "    # Input: 2 feature vectors\n",
    "    # Output: distance between them\n",
    "    def calculateDistance(self, vector1, vector2):\n",
    "        return(math.sqrt((vector1[0]-vector2[0])**2 + (vector1[1]-vector2[1])**2))\n",
    "    \n",
    "    # Calculate total weight\n",
    "    # Input: list of weights\n",
    "    # Output: total weight\n",
    "    def calculateTotalWeight(self, weight_list):\n",
    "        total_weight = 0\n",
    "        for i in range(len(weight_list)):\n",
    "            total_weight += weight_list[i][KNNAgent.INDEX_WEIGHT]\n",
    "        \n",
    "        return(total_weight)\n",
    "    \n",
    "    # Apply the kNN algorithm for feature vector and store the data point on the neighbours array\n",
    "    # Input: feature vector of current state, actions array consisting of all possible actions, list that will store knn data and weights data\n",
    "    # Output: vector containing the value of taking each action (left, neutral, right)\n",
    "    def kNNTD(self, state, actions, knn_list, weight_list):\n",
    "        approximate_action = []\n",
    "        \n",
    "        # Get the standardised version of state\n",
    "        standardised_state = self.standardiseState(state)\n",
    "        \n",
    "        # Loop through every element in the storage array and only calculate for particular action\n",
    "        for action in actions:\n",
    "            temp = [] # array consisting of tuple (distance, original index, weight) for each point in the q_storage\n",
    "            for i in range(len(self.q_storage)):\n",
    "                data = self.q_storage[i]\n",
    "                # Only want to calculate the nearest neighbour state which has the same action\n",
    "                if (data[\"action\"] == action):\n",
    "                    vector_2 = data[\"state\"]\n",
    "                    standardised_vector_2 = self.standardiseState(vector_2)\n",
    "                    distance = self.calculateDistance(standardised_state, standardised_vector_2)\n",
    "                    index = i\n",
    "                    weight = 1 / (1+distance**2) # weight formula\n",
    "            \n",
    "                    # Create the tuple and append that to temp\n",
    "                    temp.append(tuple((distance, index, weight)))\n",
    "                else:\n",
    "                    continue\n",
    "        \n",
    "            # After we finish looping through all of the point and calculating the standardise distance,\n",
    "            # Sort the tuple based on the distance and only take k of it and append that to the neighbours array\n",
    "            # We also need to calculate the total weight to make it into valid probability that we can compute it's expectation\n",
    "            sorted_temp = sorted(temp, key=lambda x: x[0])\n",
    "            for i in range(self.k):\n",
    "                try:\n",
    "                    weight_list.append(sorted_temp[i])\n",
    "                    knn_list.append(self.q_storage[sorted_temp[i][KNNAgent.INDEX_ORIGINAL]])\n",
    "                except IndexError:\n",
    "                    sys.exit(0)\n",
    "            \n",
    "            # Calculate the expected value of the action and append it to the approximate_action array\n",
    "            expected_value = 0\n",
    "            total_weight = self.calculateTotalWeight(weight_list[(action+1)*self.k:(action+1)*self.k + self.k])\n",
    "            for i in range((action+1)*self.k, (action+1)*self.k + self.k):\n",
    "                weight = weight_list[i][KNNAgent.INDEX_WEIGHT]\n",
    "                probability = weight / total_weight\n",
    "                expected_value += probability * knn_list[i][\"value\"]\n",
    "                \n",
    "            approximate_action.append(expected_value)\n",
    "        \n",
    "        return(approximate_action)\n",
    "    \n",
    "    # Select which action to choose, whether left, neutral, or right (using epsilon greedy)\n",
    "    # Output: -1 (left), 0 (neutral), 1 (right)\n",
    "    def selectAction(self):\n",
    "        # First call the knn-td algorithm to determine the value of each Q(s,a) pairs\n",
    "        action_value = self.kNNTD(self.state, KNNAgent.ACTIONS, self.knn, self.weight)\n",
    "        \n",
    "        # Use the epsilon-greedy method to choose value\n",
    "        random_number = random.uniform(0.0, 1.0)\n",
    "        if (random_number <= KNNAgent.EPSILON):\n",
    "            action_chosen = random.randint(-1, 1)\n",
    "        else:\n",
    "            # Return the action with highest Q(s,a)\n",
    "            possible_index = self.findAllIndex(max(action_value), action_value)\n",
    "            action_chosen = possible_index[random.randrange(len(possible_index))] - 1\n",
    "        \n",
    "        # Only store chosen data in the knn and weight list\n",
    "        # Clearance step\n",
    "        chosen_knn = []\n",
    "        chosen_weight = []\n",
    "        for i in range(self.k*(action_chosen+1), self.k*(action_chosen+1) + self.k):\n",
    "            chosen_knn.append(self.knn[i])\n",
    "            chosen_weight.append(self.weight[i])\n",
    "        self.knn = chosen_knn\n",
    "        self.weight = chosen_weight\n",
    "\n",
    "        return action_chosen\n",
    "    \n",
    "    # Calculate TD target based on Q Learning/ SARSAMAX\n",
    "    # Input: Immediate reward based on what the environment gave\n",
    "    # Output: TD target based on off policy Q learning\n",
    "    def calculateTDTarget(self, immediate_reward):\n",
    "        # Consider condition on the final state, return 0 immediately\n",
    "        if (immediate_reward == KNNAgent.REWARD_TERMINAL):\n",
    "            return(immediate_reward)\n",
    "        \n",
    "        knn_prime = []\n",
    "        weight_prime = []\n",
    "        action_value = self.kNNTD(self.state, KNNAgent.ACTIONS, knn_prime, weight_prime)\n",
    "        \n",
    "        return(immediate_reward + KNNAgent.GAMMA*max(action_value))\n",
    "    \n",
    "    # Q learning TD updates on every neighbours on the kNN based on the contribution that are calculated using probability weight\n",
    "    # Input: Immediate reward based on what the environment gave\n",
    "    def TDUpdate(self, immediate_reward, alpha):\n",
    "        self.alpha = alpha\n",
    "        # First, calculate the TD target\n",
    "        td_target = self.calculateTDTarget(immediate_reward)\n",
    "        \n",
    "        # Iterate every kNN and update using Q learning method based on the weighting\n",
    "        total_weight = self.calculateTotalWeight(self.weight)\n",
    "        for i in range(len(self.weight)):\n",
    "            index = self.weight[i][KNNAgent.INDEX_ORIGINAL]\n",
    "            probability = self.weight[i][KNNAgent.INDEX_WEIGHT] / total_weight\n",
    "            \n",
    "            # Begin updating\n",
    "            td_error = td_target - self.q_storage[index][\"value\"]\n",
    "            self.q_storage[index][\"value\"] = self.q_storage[index][\"value\"] + self.alpha*td_error*probability\n",
    "        \n",
    "        self.cleanList() # clean list to prepare for another step\n",
    "            \n",
    "    # Clear the knn list and also the weight list\n",
    "    def cleanList(self):\n",
    "        self.knn = []\n",
    "        self.weight = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main purpose of this program is to tune the best k parameter/ number of nearest neighbours to use for the  KNN-TD approach described and implemented on [PNA.ipynb](https://github.com/maleakhiw/Pessimistic-Neighbourhood-Aggregation-for-States-in-Reinforcement-Learning/blob/master/PNA.ipynb). The main approach that is used for this purpose is by trying k (number of nearest neighbours) starting from 4 up to considering all points as neighbours. From there, results are generated and inspected for each k which we will choose the best k leading to convergence. The environment that will be used is Mountain Car."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate decaying alphas\n",
    "# Input: minimum alpha, number of episodes\n",
    "# Output: list containing alpha\n",
    "def generateAlphas(minimum_alpha, n_episodes):\n",
    "    return(np.linspace(1.0, MIN_ALPHA, N_EPISODES))\n",
    "\n",
    "N_EPISODES = 50\n",
    "MIN_ALPHA = 0.02\n",
    "alphas = generateAlphas(MIN_ALPHA, N_EPISODES)\n",
    "\n",
    "# Initialise the environment and the agent\n",
    "size = 1000 # size of the q_storage \n",
    "k = 4 # knn parameter, this is just for initialisation, but later will be change below\n",
    "agent = KNNAgent(size, k)\n",
    "mountain_car_environment = MountainCarEnvironment(agent)\n",
    "\n",
    "# Ranges of k (this is based for previous experience, simulate many times to test previous experiment whether it holds)\n",
    "largest_k_chosen = 20\n",
    "smallest_k_chosen = 4\n",
    "\n",
    "# Store initial q storage\n",
    "initial_q_storage = agent.q_storage\n",
    "\n",
    "# Store number of steps for each k\n",
    "k_step = [0 for i in range(20-4+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAf0AAAFpCAYAAACWO/HdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIP4fKaoaNI8p6dQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x282d1322f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for e in range(1, 5):\n",
    "    for k_param in range(smallest_k_chosen, largest_k_chosen + 1):\n",
    "        # Iterate the process, train the agent (training_iteration episodes)\n",
    "        training_iteration = N_EPISODES\n",
    "        total_step = 0\n",
    "        agent.k = k_param\n",
    "        agent.q_storage = initial_q_storage\n",
    "        useless_k = False\n",
    "        for i in range(training_iteration):\n",
    "            step = 0\n",
    "            alpha = alphas[i]\n",
    "            mountain_car_environment.reset()\n",
    "            while (True):\n",
    "                action = agent.selectAction()\n",
    "                next_state = mountain_car_environment.nextState(action)\n",
    "        \n",
    "                # Change agent current state and getting reward\n",
    "                agent.state = next_state\n",
    "                immediate_reward = mountain_car_environment.calculateReward()\n",
    "                step += 1\n",
    "        \n",
    "                # Test for successful learning\n",
    "                if (immediate_reward == MountainCarEnvironment.REWARD_TERMINAL):\n",
    "                    agent.TDUpdate(immediate_reward, alpha)\n",
    "                    total_step += step\n",
    "                    break\n",
    "        \n",
    "                # Update using Q Learning and kNN\n",
    "                agent.TDUpdate(immediate_reward, alpha)\n",
    "            \n",
    "                # Prevent not converge at all or too long to converge\n",
    "                if (step >= 500000):\n",
    "                    useless_k = True\n",
    "                    total_step = sys.maxsize\n",
    "                    break\n",
    "                \n",
    "                if (total_step > 500000):\n",
    "                    useless_k = True\n",
    "                    total_step = sys.maxsize\n",
    "                    break\n",
    "        \n",
    "            if (useless_k):\n",
    "                break\n",
    "    \n",
    "        # After finishing all episodes required, calculate how many step taken during that period\n",
    "        k_step[k_param - smallest_k_chosen] = (k_step[k_param - smallest_k_chosen] * (e-1) + total_step) / e\n",
    "    \n",
    "        # Graph dynamically\n",
    "        clear_output(wait=True)\n",
    "        y = k_step\n",
    "        x = np.arange(4, 4 + len(y))\n",
    "        plt.scatter(x, y)\n",
    "        plt.title(\"Total Steps vs K\", fontsize=16)\n",
    "        plt.xlabel(\"K\")\n",
    "        plt.ylabel(\"Total Steps\")\n",
    "    \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"The best k which minimise total steps is k = {}.\".format(knn_step.index(min(k_step)) + smallest_k_chosen)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
